---
title: "FC layer의 convolution으로의 대체(FC layer의 패러다임의 변화)"
tags: [basicAI]
categories:
  - math-statistics-etc
date: 2023-05-18
toc : true
---

## Fully connected Layer에 대한 패러다임의 변화(FC → Conv대체)

### 결론

- **더 이상 FC레이어로 딥러닝 input size의 제한을 둘 필요가 없다. FC를 Convolution layer로 대체하자**

### Alexnet의 예시로 본 FC레이어의 패러다임 변화

기존의 딥러닝 모델 Alexnet의 예시로 보면, FC layer 때문에 input size가 224x224로 고정되어 있었다.

- 기존 : 7x7x512 →  1 x 1 x 25088(flatten)→ 1x1x4096(nn연산) → 1x1x4096(nn연산) → 1x1x1000(nn연산)
- 변경 : 7x7x512(7x7x 512 필터 4096개 사용) → 1x1x4096(1x1x4096필터를 4096개 적용) → 1x1x4096(1x1x4096필터를 4096개 적용) → 1x1x1000(1x1x4096 필터를 1000개 적용)
- FC를 Conv로 바꾸는 순간 Input-size의 변화를 줄 수 있다.
    
    → 448x448x3의 이미지가 들어오면 최종 결과물이 2x2x1000이 됨
    
    → 결과를 global average pooling을 하면 동일한 1x1x1000의 결과를 얻을 수 있음
    

### **이미지 사이즈 변경에 따른 문제점**

- 기존 학습 모델에 이미지가 달라진 Input이 들어온다면, 해당 이미지의 distribution을 제대로 표현 못할 수 있음 → 그러면 robust하게 다양한 사이즈의 이미지를 학습해주면 됨!

→ Yolo가 FC를 빼고 Global average pooling을 쓴 이유가 이 이론으로 설명할 수 있게 됨