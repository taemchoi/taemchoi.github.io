---
title: "TimeSeries Window Dataset"
tags: [AI, Timeseries, Dataset, 코드 구현, Forecasting]
categories:
  - Forecasting
date: 2021-12-23
toc : true
---

- [Purpose](#1-purpose)
- [TimeSeries Dataset](#2-timeseries-dataset)
- [Understanding by way of Example](#3-understanding-by-way-of-example)
- [Code Implement](#4-code-implement)

## 1. Purpose
- 딥러닝의 시계열 예측을 위한 `시계열 데이터셋` 구축
- 간단한 예시와 코드 구현을 통한 이론적 이해

## 2. TimeSeries Dataset
- 시계열 데이터셋을 구성하는 이유는 아래와 같은 목표에서 시작하게 된다.
- **"앞의 3시간의 데이터를 보고 뒤에 2시간을 예측하는 모델을 만들고 싶어"**
- 그러면 이를 구성하려면 어떻게 해야할까?
- 시간당 1개인 총 10시간의 데이터가 있다고 하면 이를 앞에서부터 차례대로 시계열 데이터셋을 만들 수 있다.
    - 1~3시를 보고 4~5시를 예측
    - 2~4시를 보고 5~6시를 예측 
    - 3~5시를 보고 6~7시를 예측
    - 4~6시를 보고 7~8시를 예측
    - 5~7시를 보고 8~9시를 예측
    - 6~8시를 보고 9~10시를 예측
- 이를 그림과 좀 더 구체적으로 `3. Understanding by way of Example`에서 다시 보자 

## 3. Understanding by way of Example
<p align="center" style="font-size:small"><img src="/img/fc8-0.png">TimeSeries Dataset</p>
- 위의 그림과 같이 총 길이가 10인 시계열 데이터셋이 있다고 가정하고
- 똑같이 10시간의 데이터를 앞에 3시간의 데이터를 보고 뒤의 2시간을 예측하는 모델을 만들면 아래와 같다.
<p align="center" style="font-size:small"><img src="/img/fc8-1.png">Dataset 1</p>
- 이 그림에서 갑자기 window, stride, shift 등 다양한 개념이 등장하는데 차근차근 설명해보려 한다.
    - **Input window : 앞에 몇 시간을 볼 것이냐를 의미한다. 즉 3시간을 볼 것이므로 3이 된다.
    - Output window : 몇 시간을 예측할 것이냐를 의미한다. 2시간을 예측할 것이니 2가 된다.
    - Stirde : 몇시간씩 띄엄띄엄 데이터셋을 구성할 것이냐를 의마한다. 위의 예제에서는 1~3을보고 바로 1시간 뒤인 2~4를 보기 때문에 1이 된다.
    - Shift : 바로 뒷시간을 예측할 건지 아니면 간격을 두고 예측할 것인지를 의미한다. 위의 예제에서는 1~3을 보고 바로 뒤인 4~5시간을 예측하기 때문에 shift는 0이다. 1~3을보고 5~6시간을 본다면 shift는 1이 될 것이다.
    - Total window : 총 시계열 데이터셋의 길이라고 보면 된다. 위의 4가지 조건을 설정하고 데이터셋을 구성했을 때의 길이로 수식은 *[그림 TimeSeries Dataset]* 에서 확인할 수 있다.
    - shape : 데이터셋의 모양이다. 
        - Train Dataset = (Total window, input window, num features)
        - Label = (Total window, output window)
    - num features : 시계열의 독립변수 수인데 여기서는 univariate로 단일이기 때문에 1이 된다.
- 위의 다양한 예제를 통해 shift와 stride의 역할을 보자
- **stride=2, shift=0**인 경우는 아래와 같다.
    - stride가 2이기 떄문에 train dataset이 123 다음, 234가 아닌 345가 오는 것을 확인할 수 있다.
<p align="center" style="font-size:small"><img src="/img/fc8-2.png">Dataset 2</p>

- **stride=2, shift=1**인 경우는 아래와 같다.
    - shift가 1이기 때문에 train dataset이 123일 때, label이 45가 아닌 56이 오는 것을 확인할 수 있다. 
<p align="center" style="font-size:small"><img src="/img/fc8-3.png">Dataset 3</p>

## 4. Code Implement
- 이는 더 복잡한 예제로 잘 알려진 Electricity 데이터셋으로 TimeSeries Dataset을 구성해보자.
- 데이터셋의 형태는 아래와 같다.
     - 간단히 설명하면 전기발전소는 총 60개가 있다.
     - 시계열은 각 발전소 별 '20년 6월 1일 부터 '20년 8월 24일까지 24시간 단위로 존재한다.
     - 예측해야하는 레이블이 전력사용량이고 
     - 우리는 독립변수로 전력사용량 column부터 태양광보유까지 모두 사용할 것이다.
     - 그리고 전력소별 개별 모델이 아닌 임베딩을 통한 하나의 모델로 구성할 것이다.
<p align="center" style="font-size:small"><img src="/img/fc8-4.jpg">Electrictiy Dataset</p>

- 순서는 아래와 같다.
    - **① 변수 선언**

```python
category_column_name = 'num' #전력소의 종류를 알려주는 컬럼이름
num_feature = 8 #input에 사용될 특징의 갯수
label_index = 2 #레이블 컬럼의 컬럼상 위치 

category = df[category_column_name].unique().tolist() # 전력소의 종류를 리스트로 반환
num_category = len(category) # 전력소의 종류의 갯수를 구함

input_window = 24*14 # 앞의 14일을 볼 것이다.
output_window = 24 *7 # 뒤의 1주일을 예측할 것이다.
shift = 0 # input 바로 다음시간을 예측할 것이다.
stride = 1 # input은 멀리 뛰기 없이 한 칸씩 가며 데이터셋을 구성할 것이다.
```

- 다음 순서는 아래와 같다.
    - **② 전력소별 윈도우 길이를 구한다. (전력소별로 시간의 길이가 다른 것을 대비하기 위함) : window_per_category**
    - **③ 최종 데이터셋의 길이를 구한다. (최종 모델 shape로 array를 구축하고 맞게 데이터를 삽입하기 위함) : total_window_num**

```python
window_per_category=np.full((num_category), 0) # 카테고리 별 윈도우 갯수를 저장할 array 생성

for n in range(num_category):
    total = df[df[category_column_name]==category[n]].shape[0] # 해당 전력소의 전체 길이를 구하고
    num_window_per_category = (total - input_window - output_window - shift)// stride + 1 # 공식에 따라 윈도우 갯수를 구하고
    window_per_category[n] = num_window_per_category # 이를 전력소별로 저장한다.
    
total_window_num = np.sum(window_per_category) # 전력소별 데이터의 길이(윈도우의 숫자)는 총 합은 최종 데이터셋의 길이가 된다. 
```

- 다음 순서는 아래와 같다.
    -  **④ data와 label을 담을 빈 array를 준비한다.**
    -  **⑤ 카테고리별로 윈도우 데이터셋을 순차로 3 에서 만든 빈 array에 담는다.**

```python
train_x = np.zeros((total_window_num, input_window, num_feature+1)) # +1을 해주는 이유는 임베딩에 따라 전력소의 종류를 넣어주기 위함
train_y = np.zeros((total_window_num, output_window))
# train shape = (96420 ,336, 9)
# label shape = (96420, 168)

count = 0
for series in range(num_category):
    for i in range(window_per_category[series]):
        data_start = i * stride # 훈련 데이터셋의 시작점은 stride가 1이기에 0 ,1, 2, 3 이렇게 됨
        data_end = data_start + input_window # 훈련 데이터셋의 종료지점은 input 윈도우의 길이만큼임
        label_start = data_end + shift # label start는 shift가 0이기에 data가 끝나는 시점임
        label_end = label_start + output_window # label end는 label start에 output window 를 더한 시점임
        
        train_x[count, :, :-1] = df.loc[df[category_column_name]==category[series]].iloc[data_start:data_end, label_index+1:] # 순차적으로 담을 건데 전력소순서에 따라 담게 된다. 
        train_y[count, :] =  df.loc[df[category_column_name]==category[series]].iloc[label_start:label_end, label_index] 
        train_x[count, :, -1] = category[series] # train_x 의 마지막 특징은 카테고리 임베딩을 위해 어떤 전력소였음을 명시해 준다.
        count+=1 # 최종 count는 총 데이터의 길이 96420이 될것이다.
```

전체 코드는 [깃허브](https://github.com/taemchoi/AI_Implement.git) 에서 참고하세요.
